###### 1、安装与设置

`pip install NLTK`

模块安装后，可以下载NLTK自带的文本库。

```python
import nltk
nltk.download()
```

这样会打开NLTK的下载器，安装所有的包。

###### 2、用NLTK做统计分析

一般是从Text对象开始的。Text对象可以通过下面的方法用简单的字符串来创建

```python 
from nltk import word_tokenize
from nltk import Text

tokens = word_tokenize('Here is some not very interestion text')
text = Text(tokens)
```

word_tokenize 函数的参数可以是任何Python字符串。如果你手边没有任何长字符串，但是还想尝试一些功能，在NLTK库里已经内置了几本书，可以用import函数导入

`from nltk.book import *`

NLTK中把2-gram称作bigrams

```
from nltk import FreqDist
fdist = FreqDist(text6)
fdist.most_common(18)


from nltk import bigrams
bigrams = bigrams(text6)
bigramsDist = FreqDist(bigrams)
bigramsDist[("Sir", "Robin")]
```

为了搜索2-gram序列"Sir Robin"，我们需要把它分解成一个数组("Sir", "Robin")，用来匹配这个2-gram序列在频率分布中的表现方式。还有一个trigrams模块，工作方式完全相同。

```python
from nltk import ngrams
fourgrams = ngrams(text6, 4)
fourgramsDist = FreqDist(fourgrams)
fourgramsDist[("father", "smelt", "of", "elderberries")]

from nltk.book import *
from nltk import ngrams
fourgrams = ngrams(text6, 4)
for fourgram in fourgrams:
	if fourgram[0] == "cocount":
		print(fourgram)
```

###### 3、用NLTK做词性分析

```python
from nltk.book import *
from nltk import word_tokenize
text = word_tokenize(...)
from nltk import pos_tag
pos_tag(text)
```

每个单词被分开放在一个元组中，一边是单词，一边是NLTK识别的词性标记(每个词性标记的具体含义请参考下标)

![Treebank语义标记](.\img\Treebank语义标记.png)

