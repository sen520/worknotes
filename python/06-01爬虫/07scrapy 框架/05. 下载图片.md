#### 下载图片



##### 在 items 里面定义好字段

```python
import scrapy
class ScrapyImage(scrapy.Item):
    img_url = scrapy.Field()
    img_name = scrapy.Field()
```

###### 在爬虫中传值

```python
from scrapy.items import ScrapyImage

    def parseDetail(self, response):
        imageInfo = response.xpath('//div[@class="content"]//div[@class="content-pic"]/a/img')
        imageName = imageInfo.xpath('./@alt').extract_first()
        imageURL = imageInfo.xpath('./@src').extract_first()

        item = ScrapyImage()
        
        # 这里就是传递的值
        item['img_url'] = imageURL
        item['img_name'] = imageName

        yield item
```

###### 在 setting 中开启管道

```python
ITEM_PIPELINES = {
    'scrapy01.pipelines.ImagePip': 300,
}
```

###### 在 setting 中指定存储位置

```python
IMAGES_STORE = "d:/images"
```

###### 在管道中存图片

```python
from scrapy.pipelines.images import ImagesPipeline

class ImagePip(ImagesPipeline):
   
    # 这个方法最先调用
    def get_media_requests(self, item, info):
        # 第一个参数是填 图片的url，meta是元信息，我们可以通过他给其他的方法传递参数，比如 file_path
        yield scrapy.Request(item['img_url'], meta={'item': item})
	
    # 如果需要自定义的文件名，那么就可以实现这个方法，但是这个方法，没有 item，
    # 所以需要 在 get_media_requests 里面把 item 传过来，通过 meta
    
    def file_path(self, request, response=None, info=None):
        
        # request.meta['item'] 这里就是 get_media_requests 传来的参数
        item = request.meta['item']
        name = item['img_name']
        dirName = re.sub('\(.+\)', '', name)
        path = dirName + '/{}'.format(name) + '.jpg'
        
        # return 的是文件路径
        return path
```


